#!/usr/bin/env python
import ROOT, os, sys, subprocess, atexit, time
import rootUtils as ut
from XRootD import client
from XRootD.client.flags import DirListFlags, OpenFlags, MkDirFlags, QueryCode
import Monitor
import Scifi_monitoring
import Mufi_monitoring
import DAQ_monitoring
import EventDisplay_Task
import SndlhcMuonReco


def pyExit():
    print("Make suicide until solution found for freezing")
    os.system("kill " + str(os.getpid()))


atexit.register(pyExit)

from argparse import ArgumentParser

parser = ArgumentParser()
parser.add_argument(
    "-A",
    "--auto",
    dest="auto",
    help="run in auto mode online monitoring",
    default=False,
    action="store_true",
)
parser.add_argument(
    "--Nupdate",
    dest="Nupdate",
    help="frequence of updating online plots",
    default=100,
    type=int,
)
parser.add_argument(
    "--Nlast",
    dest="Nlast",
    help="last N events to analyze on file",
    default=10,
    type=int,
)
parser.add_argument(
    "--Cosmics",
    dest="cosmics",
    help="use default data stream if no beam",
    action="store_true",
    default=False,
)
parser.add_argument(
    "--sudo",
    dest="sudo",
    help="update files on EOS",
    default=False,
    action="store_true",
)

parser.add_argument(
    "-M",
    "--online",
    dest="online",
    help="online mode",
    default=False,
    action="store_true",
)
parser.add_argument(
    "--batch", dest="batch", help="batch mode", default=False, action="store_true"
)
parser.add_argument(
    "--server", dest="server", help="xrootd server", default=os.environ["EOSSHIP"]
)
parser.add_argument(
    "-r", "--runNumber", dest="runNumber", help="run number", type=int, default=-1
)
parser.add_argument(
    "-p", "--path", dest="path", help="path to data", required=False, default=""
)
parser.add_argument(
    "-praw", dest="rawDataPath", help="path to raw data", required=False, default=False
)
parser.add_argument(
    "-P",
    "--partition",
    dest="partition",
    help="partition of data",
    type=int,
    required=False,
    default=-1,
)
parser.add_argument("-d", "--Debug", dest="debug", help="debug", default=False)
parser.add_argument(
    "-cpp",
    "--convRawCPP",
    action="store_true",
    dest="FairTask_convRaw",
    help="convert raw data using ConvRawData FairTask",
    default=False,
)
parser.add_argument(
    "--withCalibration",
    action="store_true",
    dest="makeCalibration",
    help="make QDC and TDC calibration, not taking from raw data",
    default=False,
)

parser.add_argument(
    "-f",
    "--inputFile",
    dest="fname",
    help="file name for MC",
    type=str,
    default=None,
    required=False,
)
parser.add_argument(
    "-g", "--geoFile", dest="geoFile", help="geofile", required=False, default=False
)
parser.add_argument(
    "-b", "--heartBeat", dest="heartBeat", help="heart beat", default=10000, type=int
)
parser.add_argument("-c", "--command", dest="command", help="command", default="")
parser.add_argument(
    "-n", "--nEvents", dest="nEvents", help="number of events", default=-1, type=int
)
parser.add_argument(
    "-s", "--nStart", dest="nStart", help="first event", default=0, type=int
)
parser.add_argument(
    "-t", "--trackType", dest="trackType", help="DS or Scifi", default="DS"
)

parser.add_argument("--ScifiNbinsRes", dest="ScifiNbinsRes", default=100)
parser.add_argument("--Scifixmin", dest="Scifixmin", default=-2000.0)
parser.add_argument("--ScifialignPar", dest="ScifialignPar", default=False)
parser.add_argument("--ScifiResUnbiased", dest="ScifiResUnbiased", default=False)
parser.add_argument("--Mufixmin", dest="Mufixmin", default=-10.0)
parser.add_argument("--ScifiStationMasked", dest="ScifiStationMasked", default="-9")

parser.add_argument(
    "--goodEvents", dest="goodEvents", action="store_true", default=False
)
parser.add_argument("--withTrack", dest="withTrack", action="store_true", default=False)
parser.add_argument("--nTracks", dest="nTracks", default=0, type=int)
parser.add_argument("--save", dest="save", action="store_true", default=False)
parser.add_argument(
    "--sH",
    dest="saveHistos",
    action="store_true",
    default=False,
    help="save all histos not only TCanvas",
)
parser.add_argument(
    "--interactive", dest="interactive", action="store_true", default=False
)

parser.add_argument("--parallel", dest="parallel", default=1, type=int)

parser.add_argument(
    "--postScale",
    dest="postScale",
    help="post scale events, 1..10..100",
    default=-1,
    type=int,
)

options = parser.parse_args()
options.slowStream = True
if options.cosmics:
    options.slowStream = False
options.startTime = ""
options.dashboard = "/mnt/raid1/data_online/run_status.json"
options.monitorTag = ""
if (options.auto and not options.interactive) or options.batch:
    ROOT.gROOT.SetBatch(True)

# if no geofile given, use defaults according to run number
if options.runNumber < 0 and not options.geoFile:
    print("No run number given and no geoFile. Do not know what to do. Exit.")
    exit()
# RUN0: 7 Apr 2022 - 26 Jul 2022   (Run 4575 started -  test run after replacing emulsions -Ettore)
# RUN1: 26 Jul 2022 - 13 Sept 2022 (Run 4855 September 14)
# RUN2: 13 Sept 2022 - 4 Nov 2022 (Run 5172 test run after emulsion replacement)
# RUN3: 4 Nov 2022  -

if not options.geoFile:
    if options.path.find("TI18") < 0:
        if options.path.find("2022") > 0:
            options.geoFile = "geofile_sndlhc_TI18_V0_2022.root"
        if options.path.find("2023") > 0:
            options.geoFile = "geofile_sndlhc_TI18_V1_2023.root"
    else:
        if options.runNumber < 4575:
            options.geoFile = "geofile_sndlhc_TI18_V3_08August2022.root"
        elif options.runNumber < 4855:
            options.geoFile = "geofile_sndlhc_TI18_V5_14August2022.root"
        elif options.runNumber < 5172:
            options.geoFile = "geofile_sndlhc_TI18_V6_08October2022.root"
        else:
            options.geoFile = "geofile_sndlhc_TI18_V7_22November2022.root"

# to be extended for future new alignments.


def currentRun():
    with client.File() as f:
        f.open(options.server + options.dashboard)
        status, L = f.read()
        Lcrun = L.decode().split("\n")
        f.close()
    curRun, curPart, start = "", "", ""
    X = eval(Lcrun[0])
    if not (X["state"] == "running"):
        print("DAQ not running.", X)
    else:
        curRun = "run_" + str(X["run_number"]).zfill(6)
        curFile = X["currently_written_file"]
        k = curFile.rfind("data_") + 5
        curPart = int(curFile[k : k + 4])
        start = X["start_time"]
        # assume monitor file always present on DAQ server
        if options.slowStream:
            options.monitorTag = "monitoring_"
        else:
            options.monitorTag = ""
    return curRun, curPart, start


if options.auto:
    options.online = True
    # search for current run
    if options.runNumber < 0:
        curRun = ""
        while curRun.find("run") < 0:
            curRun, curPart, options.startTime = currentRun()
            if curRun.find("run") < 0:
                print("no run info, sleep 30sec.", time.ctime())
                time.sleep(30)
        options.runNumber = int(curRun.split("_")[1])
        lastRun = curRun
        if options.slowStream:
            options.partition = 0  #   monitoring file set to data_0000.root   int(curPart.split('_')[1].split('.')[0])
        else:
            options.partition = int(curPart.split("_")[1].split(".")[0])
else:
    if options.runNumber < 0:
        print("run number required for non-auto mode")
        os._exit(1)
    if options.rawDataPath:
        rawDataPath = options.rawDataPath
        # works only for runs on EOS
    elif not options.server.find("eos") < 0:
        if options.path.find("2023") > 0:
            rawDataPath = "/eos/experiment/sndlhc/raw_data/physics/2023_tmp/"
        elif options.path.find("2022") > 0:
            rawDataPath = "/eos/experiment/sndlhc/raw_data/physics/2022/"
        else:
            rawDataPath = "/eos/experiment/sndlhc/raw_data/commissioning/TI18/data/"
        options.rawDataPath = rawDataPath
        runDir = rawDataPath + "run_" + str(options.runNumber).zfill(6)
        jname = "run_timestamps.json"
        dirlist = str(
            subprocess.check_output(
                "xrdfs " + os.environ["EOSSHIP"] + " ls " + runDir, shell=True
            )
        )
        if jname in dirlist:
            with client.File() as f:
                f.open(options.server + runDir + "/run_timestamps.json")
                status, jsonStr = f.read()
            exec("date = " + jsonStr.decode())
            options.startTime = date["start_time"].replace("Z", "")
            if "stop_time" in date:
                options.startTime += " - " + date["stop_time"].replace("Z", "")

# prepare tasks:
FairTasks = []
houghTransform = False  # under construction, not yet tested
if houghTransform:
    muon_reco_task = SndlhcMuonReco.MuonReco()
    muon_reco_task.SetName("houghTransform")
    FairTasks.append(muon_reco_task)
else:
    import SndlhcTracking

    trackTask = SndlhcTracking.Tracking()
    trackTask.SetName("simpleTracking")
    FairTasks.append(trackTask)

M = Monitor.Monitoring(options, FairTasks)
if options.nEvents < 0:
    options.nEvents = M.GetEntries()
if options.postScale == 0 and options.nEvents > 100e6:
    options.postScale = 100
if options.postScale == 0 and options.nEvents > 10e6:
    options.postScale = 10
print("using postScale ", options.postScale, " for run ", options.runNumber)
monitorTasks = {}
if not options.fname:
    monitorTasks["daq"] = DAQ_monitoring.DAQ_boards()
    monitorTasks["rates"] = DAQ_monitoring.Time_evolution()
monitorTasks["Scifi_hitMaps"] = Scifi_monitoring.Scifi_hitMaps()
monitorTasks["Mufi_hitMaps"] = Mufi_monitoring.Mufi_hitMaps()
monitorTasks["Mufi_QDCcorellations"] = Mufi_monitoring.Mufi_largeVSsmall()
if options.postScale < 2:
    monitorTasks["Veto_Efficiency"] = Mufi_monitoring.Veto_Efficiency()
monitorTasks["Scifi_residuals"] = Scifi_monitoring.Scifi_residuals()  # time consuming
if options.interactive:
    monitorTasks["EventDisplay"] = EventDisplay_Task.twod()

for m in monitorTasks:
    monitorTasks[m].Init(options, M)

# monitorTasks['Veto_Efficiency'].debug  = True

if not options.auto:  # default online/offline mode
    process = []
    pid = 0
    for i in range(options.parallel):
        if options.parallel == 1:
            nstart, nstop = options.nStart, options.nStart + options.nEvents
        else:
            try:
                pid = os.fork()
            except OSError:
                print("Could not create a child process")
            print("pid", pid, i)
            if pid != 0:
                process.append(pid)
            else:
                dN = options.nEvents // options.parallel
                nstart = i * dN
                nstop = nstart + dN
                if i == (options.parallel - 1):
                    nstop = options.nEvents
        if pid == 0:
            print("start ", i, nstart, nstop)
            Tcounter = {"Monitor": 0}
            for m in monitorTasks:
                Tcounter[m] = 0

            for n in range(nstart, nstop):
                if options.postScale > 1:
                    if ROOT.gRandom.Rndm() > 1.0 / options.postScale:
                        continue
                tic = time.perf_counter_ns()
                event = M.GetEvent(n)
                toc = time.perf_counter_ns()
                Tcounter["Monitor"] += toc - tic

                if not options.online:
                    if n % options.heartBeat == 0:
                        print(
                            "--> run/event nr: %i %i %5.2F%%"
                            % (
                                M.eventTree.EventHeader.GetRunId(),
                                n,
                                (n - nstart) / (nstop - nstart) * 100,
                            )
                        )
                # assume for the moment file does not contain fitted tracks
                for m in monitorTasks:
                    tic = time.perf_counter_ns()
                    monitorTasks[m].ExecuteEvent(M.eventTree)
                    toc = time.perf_counter_ns()
                    Tcounter[m] += toc - tic
            for m in monitorTasks:
                monitorTasks[m].Plot()
            txt = ""
            for x in Tcounter:
                txt += x + ":%5.1Fs " % (Tcounter[x] / 1e9)
            print("timing performance:", txt)
            if options.parallel > 1:  # save partitions
                ut.writeHists(M.h, "tmp" + str(options.runNumber) + "p" + str(i))
                exit(0)
    if options.parallel > 1:
        while process:
            pid, exit_code = os.wait()
            if pid == 0:
                time.sleep(100)
            else:
                print("child process has finished", len(process) - 1, pid, exit_code)
                process.remove(pid)
        for i in range(options.parallel):
            tmp = "tmp" + str(options.runNumber) + "p" + str(i)
            if tmp in os.listdir("."):
                ut.readHists(M.h, tmp)
            else:
                print("file missing ", tmp)
        M.presenterFile.Close()
        M.presenterFile = ROOT.TFile("run" + M.runNr + ".root", "update")

        for m in monitorTasks:
            monitorTasks[m].Plot()
        # check if all events had been processed
        if "Etime" in M.h:
            if not M.h["Etime"].GetEntries() == options.nEvents:
                print(
                    "event count failed! Processed:",
                    M.h["Etime"].GetEntries(),
                    " total number of events:",
                    options.nEvents,
                )
            else:
                print("i am finished, all events processed")
    if options.saveHistos:
        ut.writeHists(M.h, "allHistos-run" + M.runNr + ".root")

    M.publishRootFile()
    if options.sudo:
        print(options.runNumber, options.startTime)
        options.startTime += " #events=" + str(options.nEvents)
        M.updateHtml()
else:
    """ auto mode
       check for open data file on the online machine
       analyze N events
       re-open file and check for new events,
       if none available,
         check every 5 seconds: if no new file re-open again
         if new file, finish run, publish histograms, and restart with new file
   """
    N0 = 0
    if options.slowStream:
        lastPart = 0  #   reading from second low speed DAQ stream    tmp[len(tmp)-1]
    nLast = options.nEvents
    nStart = nLast - options.Nlast
    if not options.interactive and options.sudo:
        M.updateHtml()
    lastFile = M.converter.fiN.GetName()
    if not options.slowStream:
        tmp = lastFile.split("/")
        lastRun = tmp[len(tmp) - 2].replace("monitoring_", "")
        lastPart = tmp[len(tmp) - 1]

    M.updateSource(lastFile)
    while 1 > 0:
        for n in range(nStart, nLast):
            event = M.GetEvent(n)
            N0 += 1
            # trackTask.event = event
            for m in monitorTasks:
                monitorTasks[m].ExecuteEvent(M.eventTree)
            # update plots
            if N0 % options.Nupdate == 0 or N0 == int(options.Nupdate / 10):
                for m in monitorTasks:
                    monitorTasks[m].Plot()
                if options.sudo:
                    M.publishRootFile()

        M.updateSource(lastFile)
        newEntries = M.GetEntries()
        if newEntries > nLast:
            nStart = max(nLast, newEntries - options.Nlast)
            nLast = newEntries
        else:
            # check if file has changed
            curRun, curPart, options.startTime = currentRun()
            while curRun.find("run") < 0:
                curRun, curPart, options.startTime = currentRun()
                if curRun.find("run") < 0:
                    print("sleep 300sec.", curRun, time.ctime())
                    time.sleep(300)
            if not curRun == lastRun:
                for m in monitorTasks:
                    if not options.interactive:
                        monitorTasks[m].Plot()
                print("run ", lastRun, " has finished.")
                quit()  # reinitialize everything with new run number
            if not curPart == lastPart and not options.slowStream:
                lastPart = curPart
                lastFile = (
                    options.server
                    + options.path
                    + options.monitorTag
                    + lastRun
                    + "/"
                    + lastPart
                )
                M.converter.fiN = ROOT.TFile.Open(lastFile)
            else:
                time.sleep(10)  # sleep 10 seconds and check for new events
                print(
                    "DAQ inactive for 10sec. Last event = ",
                    M.GetEntries(),
                    curRun,
                    curPart,
                    N0,
                )
                nStart = nLast
